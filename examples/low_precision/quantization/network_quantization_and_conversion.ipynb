{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network conversion and weight/activation quantization\n",
    "\n",
    "This script will load an originally network prototxt file as well as pre trained weights and produces a network file whoch can be loaded by NullHop and run on FPGA\n",
    "\n",
    "Example case **VGG16:**\n",
    "\n",
    "network protoxt file can be found either in caffe_lp/examples/low_precision/imagenet/models or here:\n",
    "\n",
    "https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md\n",
    "\n",
    "caffemodel (original pre trained weights)\n",
    "\n",
    "http://www.robots.ox.ac.uk/%7Evgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from caffe.quantization.net_descriptor import net_prototxt\n",
    "from caffe.quantization.qmf_check import distribute_bits\n",
    "from caffe.quantization.convert_weights import convert_weights\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# initialize classes\n",
    "d = distribute_bits()\n",
    "n = net_prototxt()\n",
    "c = convert_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The information flow is as follow:\n",
    "1) Create a folder for a given network you want to quantize/fine tune\n",
    "   in caffe_lp/examples/low_precision/quantization/network\n",
    "2) Download and copy .caffemodel file into weight directory (e.g. HDD or wherever you want)\n",
    "   The copied original file is used to convert blobs (weight W and biases b) into low precision blob structure\n",
    "3) All models, e.g. prototxt files, are stored in caffe_lp/examples/low_precision/imagenet/models\n",
    "   We start from the deploy files as they are normally released\n",
    "4) We distribute the available bits (e.g. 16 bit including sign) for each layer separately for weights and activations\n",
    "5) We extract the network structure from a given net using extract function within net_prototxt\n",
    "6) We create a new prototxt file based on extracted network layout and layer-wise bit distribution \n",
    "   for weights and activations\n",
    "7) We finetune the model using the reduced bit precision for 1-5 Epochs\n",
    "\n",
    "Author: Moritz Milde\n",
    "Date: 03.11.2016\n",
    "email: mmilde@ini@uzh.ch\n",
    "'''\n",
    "\n",
    "net_name = 'VGG16'\n",
    "n_bits = 16\n",
    "\n",
    "caffe_root = '/home/moritz/Repositories/caffe_lp/'\n",
    "weight_dir = '/media/moritz/Data/ILSVRC2015/pre_trained/'\n",
    "model_dir = 'examples/low_precision/imagenet/models/'\n",
    "script_dir = caffe_root + 'examples/low_precision/imagenet/'\n",
    "layer_dir = 'examples/create_prototxt/layers/'\n",
    "save_dir = caffe_root + 'examples/low_precision/imagenet/models/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /media/moritz/Data/ILSVRC2015/pre_trained/VGG16/\n",
      "File already downloaded\n",
      "Doing forward pass for low precision network\n",
      "Done.\n",
      "Saving done caffemodel to /media/moritz/Data/ILSVRC2015/pre_trained/VGG16/HP_VGG16_v2.caffemodel\n"
     ]
    }
   ],
   "source": [
    "# converting pre trained caffemodel to low precision blob architecture\n",
    "c.convert_weights(net_name, save_name=None, \n",
    "                   caffe_root=caffe_root, model_dir=model_dir, weight_dir=weight_dir, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if network was already simulated... \n",
      "No. Doing forward pass\n",
      "Forward pass done\n",
      "Starting extracting weight distribution layer-wise\n",
      "-------------------\n",
      "Layer conv1_1: Max: 2.06404\n",
      "Layer conv1_1: Min: -0.0158289\n",
      "conv1_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 2 \n",
      "Number of fractional bits: 14\n",
      "After optimaization:\n",
      "Number of integer bits: 3 \n",
      "Number of fractional bits: 13\n",
      "Done: conv1_1\n",
      "-------------------\n",
      "Layer conv1_2: Max: 0.905218\n",
      "Layer conv1_2: Min: -1.02715\n",
      "conv1_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv1_2\n",
      "-------------------\n",
      "Layer conv2_1: Max: 0.365474\n",
      "Layer conv2_1: Min: -0.179221\n",
      "conv2_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv2_1\n",
      "-------------------\n",
      "Layer conv2_2: Max: 0.633758\n",
      "Layer conv2_2: Min: -0.595335\n",
      "conv2_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv2_2\n",
      "-------------------\n",
      "Layer conv3_1: Max: 0.349496\n",
      "Layer conv3_1: Min: -0.200979\n",
      "conv3_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv3_1\n",
      "-------------------\n",
      "Layer conv3_2: Max: 0.274845\n",
      "Layer conv3_2: Min: -0.181249\n",
      "conv3_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv3_2\n",
      "-------------------\n",
      "Layer conv3_3: Max: 0.594772\n",
      "Layer conv3_3: Min: -0.142888\n",
      "conv3_3\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv3_3\n",
      "-------------------\n",
      "Layer conv4_1: Max: 0.314845\n",
      "Layer conv4_1: Min: -0.145482\n",
      "conv4_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv4_1\n",
      "-------------------\n",
      "Layer conv4_2: Max: 0.182376\n",
      "Layer conv4_2: Min: -0.0842845\n",
      "conv4_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv4_2\n",
      "-------------------\n",
      "Layer conv4_3: Max: 0.337665\n",
      "Layer conv4_3: Min: -0.198359\n",
      "conv4_3\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv4_3\n",
      "-------------------\n",
      "Layer conv5_1: Max: 0.639749\n",
      "Layer conv5_1: Min: -0.350803\n",
      "conv5_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv5_1\n",
      "-------------------\n",
      "Layer conv5_2: Max: 0.759767\n",
      "Layer conv5_2: Min: -0.917106\n",
      "conv5_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: conv5_2\n",
      "-------------------\n",
      "Layer conv5_3: Max: 9.43155\n",
      "Layer conv5_3: Min: -0.500367\n",
      "conv5_3\n",
      "Before optimaization:\n",
      "Number of integer bits: 4 \n",
      "Number of fractional bits: 12\n",
      "After optimaization:\n",
      "Number of integer bits: 5 \n",
      "Number of fractional bits: 11\n",
      "Done: conv5_3\n",
      "-------------------\n",
      "Layer fc6: Max: 0.855507\n",
      "Layer fc6: Min: -0.780053\n",
      "fc6\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: fc6\n",
      "-------------------\n",
      "Layer fc7: Max: 1.21546\n",
      "Layer fc7: Min: -0.0123399\n",
      "fc7\n",
      "Before optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "After optimaization:\n",
      "Number of integer bits: 2 \n",
      "Number of fractional bits: 14\n",
      "Done: fc7\n",
      "-------------------\n",
      "Layer fc8: Max: 0.661554\n",
      "Layer fc8: Min: -0.773357\n",
      "fc8\n",
      "Before optimaization:\n",
      "Number of integer bits: 0 \n",
      "Number of fractional bits: 16\n",
      "After optimaization:\n",
      "Number of integer bits: 1 \n",
      "Number of fractional bits: 15\n",
      "Done: fc8\n",
      "-------------------\n",
      "Checking if network was already simulated... \n",
      "Yes\n",
      "Bit distribution activation: (2, 16)\n",
      "Starting extracting activation distribution layer-wise\n",
      "-------------------\n",
      "Layer conv1_1: Max: 827.358\n",
      "Layer conv1_1: Min: 2.38419e-07\n",
      "conv1_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 10 \n",
      "Number of fractional bits: 6\n",
      "After optimaization:\n",
      "Number of integer bits: 11 \n",
      "Number of fractional bits: 5\n",
      "Done: conv1_1\n",
      "-------------------\n",
      "Layer conv1_2: Max: 4171.07\n",
      "Layer conv1_2: Min: 1.60933e-06\n",
      "conv1_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 13 \n",
      "Number of fractional bits: 3\n",
      "After optimaization:\n",
      "Number of integer bits: 14 \n",
      "Number of fractional bits: 2\n",
      "Done: conv1_2\n",
      "-------------------\n",
      "Layer conv2_1: Max: 6665.55\n",
      "Layer conv2_1: Min: 5.99027e-06\n",
      "conv2_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 13 \n",
      "Number of fractional bits: 3\n",
      "After optimaization:\n",
      "Number of integer bits: 14 \n",
      "Number of fractional bits: 2\n",
      "Done: conv2_1\n",
      "-------------------\n",
      "Layer conv2_2: Max: 12353.4\n",
      "Layer conv2_2: Min: 1.27852e-05\n",
      "conv2_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 14 \n",
      "Number of fractional bits: 2\n",
      "After optimaization:\n",
      "Number of integer bits: 15 \n",
      "Number of fractional bits: 1\n",
      "Done: conv2_2\n",
      "-------------------\n",
      "Layer conv3_1: Max: 14580.8\n",
      "Layer conv3_1: Min: 5.54081e-05\n",
      "conv3_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 14 \n",
      "Number of fractional bits: 2\n",
      "After optimaization:\n",
      "Number of integer bits: 15 \n",
      "Number of fractional bits: 1\n",
      "Done: conv3_1\n",
      "-------------------\n",
      "Layer conv3_2: Max: 15778.2\n",
      "Layer conv3_2: Min: 5.28935e-05\n",
      "conv3_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 14 \n",
      "Number of fractional bits: 2\n",
      "After optimaization:\n",
      "Number of integer bits: 15 \n",
      "Number of fractional bits: 1\n",
      "Done: conv3_2\n",
      "-------------------\n",
      "Layer conv3_3: Max: 13960.5\n",
      "Layer conv3_3: Min: 0.00014418\n",
      "conv3_3\n",
      "Before optimaization:\n",
      "Number of integer bits: 14 \n",
      "Number of fractional bits: 2\n",
      "After optimaization:\n",
      "Number of integer bits: 15 \n",
      "Number of fractional bits: 1\n",
      "Done: conv3_3\n",
      "-------------------\n",
      "Layer conv4_1: Max: 10155.3\n",
      "Layer conv4_1: Min: 1.90847e-05\n",
      "conv4_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 14 \n",
      "Number of fractional bits: 2\n",
      "After optimaization:\n",
      "Number of integer bits: 15 \n",
      "Number of fractional bits: 1\n",
      "Done: conv4_1\n",
      "-------------------\n",
      "Layer conv4_2: Max: 6312.55\n",
      "Layer conv4_2: Min: 7.4625e-05\n",
      "conv4_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 13 \n",
      "Number of fractional bits: 3\n",
      "After optimaization:\n",
      "Number of integer bits: 14 \n",
      "Number of fractional bits: 2\n",
      "Done: conv4_2\n",
      "-------------------\n",
      "Layer conv4_3: Max: 3449.77\n",
      "Layer conv4_3: Min: 1.48695e-05\n",
      "conv4_3\n",
      "Before optimaization:\n",
      "Number of integer bits: 12 \n",
      "Number of fractional bits: 4\n",
      "After optimaization:\n",
      "Number of integer bits: 13 \n",
      "Number of fractional bits: 3\n",
      "Done: conv4_3\n",
      "-------------------\n",
      "Layer conv5_1: Max: 2150.29\n",
      "Layer conv5_1: Min: 0.000145921\n",
      "conv5_1\n",
      "Before optimaization:\n",
      "Number of integer bits: 12 \n",
      "Number of fractional bits: 4\n",
      "After optimaization:\n",
      "Number of integer bits: 13 \n",
      "Number of fractional bits: 3\n",
      "Done: conv5_1\n",
      "-------------------\n",
      "Layer conv5_2: Max: 922.957\n",
      "Layer conv5_2: Min: 0.000232324\n",
      "conv5_2\n",
      "Before optimaization:\n",
      "Number of integer bits: 10 \n",
      "Number of fractional bits: 6\n",
      "After optimaization:\n",
      "Number of integer bits: 11 \n",
      "Number of fractional bits: 5\n",
      "Done: conv5_2\n",
      "-------------------\n",
      "Layer conv5_3: Max: 618.295\n",
      "Layer conv5_3: Min: 4.21852e-05\n",
      "conv5_3\n",
      "Before optimaization:\n",
      "Number of integer bits: 10 \n",
      "Number of fractional bits: 6\n",
      "After optimaization:\n",
      "Number of integer bits: 11 \n",
      "Number of fractional bits: 5\n",
      "Done: conv5_3\n",
      "-------------------\n",
      "Layer fc6: Max: 58.7457\n",
      "Layer fc6: Min: 0.000577942\n",
      "fc6\n",
      "Before optimaization:\n",
      "Number of integer bits: 6 \n",
      "Number of fractional bits: 10\n",
      "After optimaization:\n",
      "Number of integer bits: 7 \n",
      "Number of fractional bits: 9\n",
      "Done: fc6\n",
      "-------------------\n",
      "Layer fc7: Max: 18.4741\n",
      "Layer fc7: Min: 3.618e-05\n",
      "fc7\n",
      "Before optimaization:\n",
      "Number of integer bits: 5 \n",
      "Number of fractional bits: 11\n",
      "After optimaization:\n",
      "Number of integer bits: 6 \n",
      "Number of fractional bits: 10\n",
      "Done: fc7\n",
      "-------------------\n",
      "Layer fc8: Max: 35.192\n",
      "Layer fc8: Min: -10.2964\n",
      "fc8\n",
      "Before optimaization:\n",
      "Number of integer bits: 6 \n",
      "Number of fractional bits: 10\n",
      "After optimaization:\n",
      "Number of integer bits: 7 \n",
      "Number of fractional bits: 9\n",
      "Done: fc8\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "# We first have to estimate the bit distribution for weights and activations\n",
    "# since the network will be constructed based on this estimate\n",
    "# Make sure you downloaded the pre_trained weights from the above link, if VGG16/GoogLeNet, or the respective source\n",
    "# The naming convention is: NetworkName_deploy.prototxt (for test/one-time rounding)\n",
    "#                           NetworkName_train.prototxt (for finetune/re-train)\n",
    "bit_w, net = d.weights(net_name=net_name, n_bits=n_bits, load_mode='high_precision', threshold=0.0,\n",
    "                       caffe_root=caffe_root, model_dir=model_dir, weight_dir=weight_dir, debug=True)\n",
    "bit_a, net = d.activation(net_name=net_name, n_bits=n_bits, load_mode='high_precision', threshold=0.0,\n",
    "                          caffe_root=caffe_root, model_dir=model_dir, weight_dir=weight_dir, debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting network structure\n",
      "['64C3S1p1', 'A', 'ReLU', '64C3S1p1', 'A', 'ReLU', '2P2', '128C3S1p1', 'A', 'ReLU', '128C3S1p1', 'A', 'ReLU', '2P2', '256C3S1p1', 'A', 'ReLU', '256C3S1p1', 'A', 'ReLU', '256C3S1p1', 'A', 'ReLU', '2P2', '512C3S1p1', 'A', 'ReLU', '512C3S1p1', 'A', 'ReLU', '512C3S1p1', 'A', 'ReLU', '2P2', '512C3S1p1', 'A', 'ReLU', '512C3S1p1', 'A', 'ReLU', '512C3S1p1', 'A', 'ReLU', '2P2', '4096F', 'A', 'ReLU', 'D5', '4096F', 'A', 'ReLU', 'D5', '1000F', 'Accuracy', 'loss']\n",
      "Creating new network based on weight/activation distribution\n"
     ]
    }
   ],
   "source": [
    "# By default the functions try to locate models within the directory in (3)!!!!\n",
    "# Make sure the desired prototxt file to extract the net structure from is in the respective directory\n",
    "print 'Extracting network structure'\n",
    "net_layout = n.extract(net_name=net_name, mode='train', model=net, \n",
    "                       caffe_root=caffe_root, weight_dir=weight_dir, debug=False)\n",
    "print net_layout\n",
    "print 'Creating new network based on weight/activation distribution'\n",
    "n.create(net_name=net_name, net_descriptor=net_layout, \n",
    "         bit_distribution_weights=bit_w, bit_distribution_act=bit_a, scale=True,\n",
    "         init_method='xavier', lp=True, deploy=False, visualize=False, round_bias='false',\n",
    "         caffe_root=caffe_root, model_dir=model_dir, layer_dir=layer_dir, save_dir=save_dir, debug=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Finetune the network\n",
    "You have to change the lp_solver_GPU0_finetune.prototxt\n",
    "located in $caffe_root/examples/low_precision/imagenet/solver\n",
    "to load the netowrk you just created LP_{net_name}_{n_bits}_bits_train.prototxt \n",
    "and the converted HP_{net_name}_v2.caffemodel\n",
    "HAPPY FINETUNING\n",
    "\n",
    "\n",
    "!!!! Please check data source and mean file path in the prototxt to match your default locations !!!\n",
    "!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd caffe_root/examples/low_precision/imagenet\n",
    "gedit finetune.sh\n",
    "gedit solver/lp_solverGPU0_finetune.prototxt\n",
    "./finetune.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
