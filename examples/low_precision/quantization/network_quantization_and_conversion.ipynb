{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network conversion and weight/activation quantization\n",
    "\n",
    "This script will load an originally network prototxt file as well as pre trained weights and produces a network file whoch can be loaded by NullHop and run on FPGA\n",
    "\n",
    "Example case VGG16\n",
    "network protoxt file can be found either in caffe_lp/examples/low_precision/imagenet/models or here:\n",
    "\n",
    "https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md\n",
    "\n",
    "caffemodel (original pre trained weights)\n",
    "http://www.robots.ox.ac.uk/%7Evgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import caffe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from caffe.quantization.net_descriptor import net_prototxt\n",
    "from caffe.quantization.qmf_check import distribute_bits\n",
    "from caffe.quantization.convert_weights import convert_weights\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# initialize classes\n",
    "d = distribute_bits()\n",
    "n = net_prototxt()\n",
    "c = convert_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /media/moritz/Data/ILSVRC2015/pre_trained/VGG16/\n",
      "File already downloaded\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The information flow is as follow:\n",
    "1) Create a folder for a given network you want to quantize/fine tune\n",
    "   in caffe_lp/examples/low_precision/quantization/network\n",
    "2) Download and copy .caffemodel file into weight directory (e.g. HDD or wherever you want)\n",
    "   The copied original file is used to convert blobs (weight W and biases b) into low precision blob structure\n",
    "3) All models, e.g. prototxt files, are stored in caffe_lp/examples/low_precision/imagenet/models\n",
    "   We start from the deploy files as they are normally released\n",
    "4) We distribute the available bits (e.g. 16 bit including sign) for each layer separately for weights and activations\n",
    "5) We extract the network structure from a given net using extract function within net_prototxt\n",
    "6) We create a new prototxt file based on extracted network layout and layer-wise bit distribution \n",
    "   for weights and activations\n",
    "7) We finetune the model using the reduced bit precision for 1-5 Epochs\n",
    "\n",
    "Author: Moritz Milde\n",
    "Date: 03.11.2016\n",
    "email: mmilde@ini@uzh.ch\n",
    "'''\n",
    "\n",
    "net_name = 'VGG16'\n",
    "n_bits = 16\n",
    "\n",
    "caffe_root = '/home/moritz/Repositories/caffe_lp/'\n",
    "weight_dir = '/media/moritz/Data/ILSVRC2015/pre_trained/' + net_name + '/'\n",
    "model_dir = caffe_root + 'examples/low_precision/imagenet/models/'\n",
    "script_dir = caffe_root + 'examples/low_precision/imagenet/'\n",
    "layer_dir = caffe_root + 'examples/create_prototxt/layers/'\n",
    "save_dir = caffe_root + 'examples/low_precision/imagenet/models/'\n",
    "\n",
    "c.convert_weights(net_name, save_name=None, \n",
    "                  caffe_root=caffe_root, model_dir=model_dir, weight_dir=weight_dir, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We first have to estimate the bit distribution for weights and activations\n",
    "# since the network will be constructed based on this estimate\n",
    "# Make sure you downloaded the pre_trained weights from the above link, if VGG16/GoogLeNet, or the respective source\n",
    "# The naming convention is: NetworkName_deploy.prototxt (for test/one-time rounding)\n",
    "#                           NetworkName_train.prototxt (for finetune/re-train)\n",
    "bit_w, net = d.weights(net_name=net_name, n_bits=n_bits, load_mode='high_precision', threshold=0.1,\n",
    "                       caffe_root=caffe_root, model_dir=model_dir, weight_dir=weight_dir, debug=False)\n",
    "bit_a, net = d.activation(net_name=net_name, n_bits=n_bits, load_mode='high_precision', threshold=0.05,\n",
    "                          caffe_root=caffe_root, model_dir=model_dir, weight_dir=weight_dir, debug=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting network structure\n",
      "['64C3S1p1', 'A', 'ReLU', '64C3S1p1', 'A', 'ReLU', '2P2', '128C3S1p1', 'A', 'ReLU', '128C3S1p1', 'A', 'ReLU', '2P2', '256C3S1p1', 'A', 'ReLU', '256C3S1p1', 'A', 'ReLU', '256C3S1p1', 'A', 'ReLU', '2P2', '512C3S1p1', 'A', 'ReLU', '512C3S1p1', 'A', 'ReLU', '512C3S1p1', 'A', 'ReLU', '2P2', '512C3S1p1', 'A', 'ReLU', '512C3S1p1', 'A', 'ReLU', '512C3S1p1', 'A', 'ReLU', '2P2', '4096F', 'A', 'ReLU', 'D5', '4096F', 'A', 'ReLU', 'D5', '1000F', 'Accuracy', 'loss']\n",
      "Creating new network based on weight/activation distribution\n",
      "Generating LP_VGG16_16_bit_train.prototxt\n"
     ]
    }
   ],
   "source": [
    "# By default the functions try to locate models within the directory in (3)!!!!\n",
    "# Make sure the desired prototxt file to extract the net structure from is in the respective directory\n",
    "print 'Extracting network structure'\n",
    "net_layout = n.extract(net_name=net_name, mode='train', model=net, \n",
    "                       caffe_root=caffe_root, weight_dir=weight_dir, debug=False)\n",
    "print net_layout\n",
    "print 'Creating new network based on weight/activation distribution'\n",
    "n.create(net_name=net_name, net_descriptor=net_layout, \n",
    "         bit_distribution_weights=bit_w, bit_distribution_act=bit_a, scale=True\n",
    "         init_method='xavier', lp=True, deploy=False, visualize=False, round_bias='false',\n",
    "         caffe_root=caffe_root, model_dir=model_dir, layer_dir=layer_dir, save_dir=save_dir, debug=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Finetune the network\n",
    "You have to change the lp_solver_GPU0_finetune.prototxt\n",
    "located in $caffe_root/examples/low_precision/imagenet/solver\n",
    "to load the netowrk you just created LP_{net_name}_{n_bits}_bits_train.prototxt \n",
    "and the converted HP_{net_name}_v2.caffemodel\n",
    "HAPPY FINETUNING\n",
    "\n",
    "\n",
    "!!!! Please check data source and mean file path in the prototxt to match your default locations !!!\n",
    "!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd caffe_root/examples/low_precision/imagenet\n",
    "gedit finetune.sh\n",
    "gedit solver/lp_solverGPU0_finetune.prototxt\n",
    "./finetune.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
